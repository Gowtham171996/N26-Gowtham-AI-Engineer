OLLAMA_LLM_MODEL: "gemma3:1b-it-qat"
OLLAMA_EMBEDDING_MODEL: "nomic-embed-text" # Recommended for RAG tasks
OLLAMA_BASE_URL: "http://localhost:11434"
OLLAMA_TIMEOUT: 120.0
OLLAMA_WORKERS: 8

QDRANT_HOST: "localhost"
QDRANT_PORT: 6333
QDRANT_URL: "http://localhost:6333"
QDRANT_API_KEY: ""
QDRANT_TIMEOUT: 120.0
QDRANT_COLLECTION_NAME: "ai_knowledge_base"

RERANKER_MODEL: "cross-encoder/ms-marco-MiniLM-L-6-v2"

CONFIG_FILE_NAME: "config.yaml"
VECTOR_STORE_PATH: "vector_store.json"
RAG_PROMPT_TEMPLATE: "system_prompt.txt"
DATA_DIR: "data"
PERSIST_DIR : "qdrant_storage"

CHUNK_SIZE: 512
CHUNK_OVERLAP: 48

TOP_K_CHUNKS: 5   #No of chunks qdrant should retrieve
TOP_N_RERANKED: 3 #No of chunks reranker should send to LLM